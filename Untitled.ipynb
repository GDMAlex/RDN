{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 2.3 K \n",
      "1 | decoder | Decoder | 171   \n",
      "2 | loss    | Loss    | 0     \n",
      "------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import libTP\n",
    "import pandas as pd \n",
    "import pytorch_lightning as pl\n",
    "import json\n",
    "\n",
    "print(pl.__version__)\n",
    "\n",
    "###### TODO: load configuration created at the previous step\n",
    "with open('./conf/config.json') as json_file:\n",
    "    conf = json.load(json_file)\n",
    "    \n",
    "###### TODO: load feature encoder created at the previous step\n",
    "######       You can use libTP.feature_engineering.helpers\n",
    "transforms = libTP.feature_engineering.helpers.load_transforms(conf)\n",
    "###### TODO: load \"train.csv\" using pandas\n",
    "data = pd.read_csv(\"./dataset/train.csv\")\n",
    "\n",
    "###### TODO: Complete the code in libTP/models \n",
    "model = libTP.models.AutoEncoder(conf[\"network\"])\n",
    "\n",
    "###### TODO: transform dataframe (you can use libTP.feature_engineering.helpers)\n",
    "transformed = libTP.feature_engineering.helpers.transform_df(data,transforms)\n",
    "\n",
    "###### TODO: train the model. You can use functions inside libTP.misc.dataset to create\n",
    "######       a torch.Dataset complient with what pytorch_lightning is expecting\n",
    "######       Don't forget to split the dataset into 3 parts: train, evaluation, test\n",
    "######       This can be done using the split method of class libTP.misc.dataset.PandasDataset\n",
    "\n",
    "\n",
    "#Split train , val , test\n",
    "\n",
    "train , evaluation , test = libTP.misc.dataset.PandasDataset(transformed).split() #Split pour avoir train , evaluation et test \n",
    "#Batch sur train , val , test \n",
    "train_batch = libTP.misc.dataset.batch_loader(train)\n",
    "evaluation_batch = libTP.misc.dataset.batch_loader(evaluation)\n",
    "test_batch = libTP.misc.dataset.batch_loader(test)\n",
    "\n",
    "#EntraÃ®nement\n",
    "trainer = pl.Trainer(callbacks=[early_stopping, checkpoints], max_epochs=1000)\n",
    "trainer.fit(model, train_dataloader=train_batch, val_dataloaders=evaluation_batch )\n",
    "\n",
    "\n",
    "###### TODO: use the test data to calibrate the scoring functions of the autoencoder\n",
    "###### TODO: save the trained model and go on to the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-preliminary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-runner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
